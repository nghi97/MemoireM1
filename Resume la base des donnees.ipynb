{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddea6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38454f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openfile(a):#ouvrir le fichier json\n",
    "    with open(a,encoding='utf-8') as f:\n",
    "        data=json.load(f)\n",
    "        print(data.keys())\n",
    "        d1=data['data']\n",
    "        print(type(d1))\n",
    "        d2=data['includes']\n",
    "        print(type(d2))\n",
    "        d2list=list(d2.values())\n",
    "        dd=defaultdict(list)\n",
    "        ff=defaultdict(list)\n",
    "        for d in d1:\n",
    "            for key,value in d.items():\n",
    "                dd[key].append(value)\n",
    "        for i in d2list[0]:\n",
    "            for key,value in i.items():\n",
    "                ff[key].append(value)\n",
    "    df1=pd.DataFrame(data=dd)\n",
    "    df2=pd.DataFrame(data=ff)\n",
    "    names2=df2.columns.to_list()\n",
    "    names2[names2.index('id')]='author_id'\n",
    "    df2.columns=names2\n",
    "    df=pd.merge(left=df1,right=df2,on='author_id')\n",
    "    del df['id']\n",
    "    col=df.columns.to_list()\n",
    "    col=['author_id','name','username','text','created_at']\n",
    "    df=df[col]\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f4924e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n",
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "df1=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm1.json\")\n",
    "df2=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm2.json\")\n",
    "df3=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm3.json\")\n",
    "df4=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm4.json\")\n",
    "df5=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm5.json\")\n",
    "df6=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm6.json\")\n",
    "df7=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm7.json\")\n",
    "df8=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm8.json\")\n",
    "df9=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm9.json\")\n",
    "df10=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm10.json\")\n",
    "df11=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm11.json\")\n",
    "df12=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm12.json\")\n",
    "df13=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm13.json\")\n",
    "df14=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm14.json\")\n",
    "df15=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm15.json\")\n",
    "df16=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm16.json\")\n",
    "df17=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm17.json\")\n",
    "df=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16,df17],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd471706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'includes', 'meta'])\n",
      "<class 'list'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "df18=openfile(\"C:\\\\Users\\\\User\\\\Desktop\\\\Base des donnees\\\\mm18.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb31751",
   "metadata": {},
   "outputs": [],
   "source": [
    "df18.to_csv('bdd3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "115b4c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                author_id                 name         username  \\\n",
      "0     1325030356559540228  Alexandre M A Caron  Alexand14248460   \n",
      "1     1325030356559540228  Alexandre M A Caron  Alexand14248460   \n",
      "2              1469748847          GeB. ğŸ¥•ğŸ¥•ğŸ¥•ğŸ’€ğŸ’€ğŸ’€    GerardBondeau   \n",
      "3              1469748847          GeB. ğŸ¥•ğŸ¥•ğŸ¥•ğŸ’€ğŸ’€ğŸ’€    GerardBondeau   \n",
      "4              1469748847          GeB. ğŸ¥•ğŸ¥•ğŸ¥•ğŸ’€ğŸ’€ğŸ’€    GerardBondeau   \n",
      "...                   ...                  ...              ...   \n",
      "8275           3106741977                Tranq        Amael005p   \n",
      "8276           3106741977                Tranq        Amael005p   \n",
      "8277           3106741977                Tranq        Amael005p   \n",
      "8278           2214396507        Neo Start 1 ğŸ˜     CoeurSolaire   \n",
      "8279           2214396507        Neo Start 1 ğŸ˜     CoeurSolaire   \n",
      "\n",
      "                                                   text  \\\n",
      "0     Tellement fier d'Ãªtre vaccinÃ© trois fois contr...   \n",
      "1     @JeMouth Tellement fier d'Ãªtre vaccinÃ© trois f...   \n",
      "2     @DrEliDavid @idrissaberkane ğŸ”´ Si... #Moderna b...   \n",
      "3     @JeanYvesCAPO @maillardjeanch3 @alainhoupert P...   \n",
      "4     \"Lâ€™ancien responsable de la rech respiratoire ...   \n",
      "...                                                 ...   \n",
      "8275  @justsandrafyb @Ad_astra_85 C'Ã©tait pas mal co...   \n",
      "8276  @Ad_astra_85 @justsandrafyb Grave... pour le c...   \n",
      "8277  @Ad_astra_85 @justsandrafyb On a parlÃ© de toi ...   \n",
      "8278  Â«Â Casier du moment. Je suis trop fan ğŸ¥°ğŸ¤© Dessin...   \n",
      "8279  Â«Â Le shop du jour (02/01/2020). Le skin Astra ...   \n",
      "\n",
      "                    created_at  \n",
      "0     2022-04-29T15:47:14.000Z  \n",
      "1     2022-04-29T15:33:49.000Z  \n",
      "2     2022-04-29T08:46:59.000Z  \n",
      "3     2022-04-26T19:57:10.000Z  \n",
      "4     2022-04-21T17:42:44.000Z  \n",
      "...                        ...  \n",
      "8275  2020-01-06T15:23:50.000Z  \n",
      "8276  2020-01-06T14:10:13.000Z  \n",
      "8277  2020-01-06T13:57:17.000Z  \n",
      "8278  2020-01-03T17:46:20.000Z  \n",
      "8279  2020-01-02T09:13:21.000Z  \n",
      "\n",
      "[8280 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a9f052cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('bddtotal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e603fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b11c12c2f02d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"mooz\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[df['name']==\"mooz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9b45de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_name=df.drop_duplicates(subset=['username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aab4fed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_name['name'].to_csv('list_name.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8692b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.loc[df['name'].isin('Alexandre M A Caron','Alain THOMAS','Thor Odyssey','DUMONT GILLES FERNAND',\n",
    "                         'â˜£ï¸ğŸ§¹ğŸ¢Adam #Nupes 420Â®ï¸','Elwood so Good','Mer et Montagne â›·â›·â›·','jutzitsu',\n",
    "                         'Muriel FIOL','Chris Gir','palacin','BayesReality','ğŸ’®Ã‰lysÃ©e Reclus ğŸƒ#JeSauveVosViesPasVosProfits',\n",
    "                         'Rabusseau JÃ©rÃ´me','ğŸ‡¹ğŸ‡³ Radhwan âšªâ“‚ï¸','Hainaux','Didier M.Ravassard','Pat_Occitan triple non ğŸ’‰',\n",
    "                         'Amor LOUHICHI','GELY Ghislain','HÃ©bert Faucheux IrÃ¨ne ğŸ¾ğŸŒ¹ğŸ’ƒğŸ•º','Guiyom ğŸ‡«ğŸ‡·ğŸ‡µğŸ‡¹ğŸ‡¨ğŸ‡´','GOUDOT William',\n",
    "                         'Yvon Balestre ğŸ¢âœŠ','Thierry La Fronde ğŸ‡«ğŸ‡·','Pascal Marlier ğŸ´â€â˜ ï¸ğŸˆâ€â¬›','Fred !!!',\n",
    "                         'PELISSIER Patrick','Ted smith','franceamourğŸ‡«ğŸ‡·ğŸ‡¨ğŸ‡­','Christian GLT × ×•×¦×¨×™','Dominique Lang ğŸ‡ºğŸ‡¦','Philippe Coune',\n",
    "                         'BenoÃ®t AUGUSTE â“‚ï¸','â“‚ï¸artin StÃ©phane ğŸ¥•ğŸ¥•ğŸ¥•','Petit Lion âœŒï¸ğŸ¢ğŸ§¹Ï†ğŸ•Šï¸ğŸ‘¶ğŸ¼ğŸ¶ğŸ¸â›·ï¸ğŸŒï¸ğŸï¸ğŸ° @JLM20220',\n",
    "                         'MDaniel, RÃ©da.','Dominique BouffÃ©e','Tgalli ğŸ‡ªğŸ‡ºğŸ‡ºğŸ‡¦','jean pierre grosse','Yohan','Christophe LESAGE','Kamel TAGHERSOUT',\n",
    "                         'Jomard bernard','David Gil Photographies NCA','Guillaume ALLOUARD','karim','LittleMartin',\n",
    "                         'paulo sariano','Patrick Philippon','FranÃ§ois Asselineau','ğŸ’™ğŸ’› C3drick0s ğŸ‡ºğŸ‡¦ğŸ‡ºğŸ‡¦','David van Hemelryck ğŸ‡«ğŸ‡·',\n",
    "                         'ğŸ…£ğŸ…—ğŸ…ğŸ…œğŸ…ğŸ…¢ ğŸ…ŸğŸ…˜ğŸ…”ğŸ…£ğŸ…¡ğŸ…˜ ğŸŒ','ribellinu sagace Ï† ğŸŒğŸŒ³ğŸ’§ğŸ”»','Nadrake','Andy Reiben','JoJack','Darladi Lallana ğŸ”´ğŸ”´',\n",
    "                         '@HenryFlecher','henry','guillaume','Robocop michel','Paul Giacobbi','MYMYL-COM','Olivier Picot #MerciJeanLuc',\n",
    "                         'Olivier MARCHAUD â“©','deschadul','M.G1961','Nicolas JUHEL','Gobimar !','FabriceğŸ¯ | Blogging | SEO | Make moneyğŸ‡²ğŸ‡«',\n",
    "                         'ğŸ‡ºğŸ‡¦Sebastien Thos ğŸ‡ºğŸ‡¦ #APPvaccinÃ©','bailly-masson','Pascal Pointud','Etienne Jean Pierre','Laurent VIOLLEAU','Winael','Johan ğŸ ',\n",
    "                         'ğŸ‡«ğŸ‡· Steven â“‚ï¸ ğŸ‡«ğŸ‡·','ğš‚ğš ğ™·ğš˜ğš—ğš˜ğš›ğšŠÌ‚ğš ğŸŒ¿ â“ ğŸ•Š','Super Ryan 2 | Xboxlive.fr ğŸ®','Pascal Gannat #ReconquÃªte','Paul B-M','brahim',\n",
    "                         'Jean-franÃ§ois Delahaut','Nadir Boussoukaia','VANDEWALLE  Yves','Clovis_Freeman   Ù† âœ¡','HofÃ©e Semopa Ù†','F J Vanderlynden',\n",
    "                         'Gio ğŸŒ','Anthony Radvanszky de RğŸ‡­ğŸ‡ºğŸ‡¨ğŸ‡µ','Æsus','VOLLMER Marc','ğŸ‡§ğŸ‡· Erivan Feitosa ğŸ‡§ğŸ‡·','Leleu Fabien','Tristan Turquois',\n",
    "                         'gabriel','Toumix','Henri Bourjade','JoÃ«l Yvon Martin #Z (Je bloque les trolls #Macron)','Dario','jacques','NoÃ«l-Flantier',\n",
    "                         'lohpf alain',)]:\n",
    "    df['Sexe']='H'\n",
    "    \n",
    "elif df.loc[df['name'].isin('Stitoududu/2077#AmishğŸ€','Ariane','sabine dumas','elisabeth Rouzier',\n",
    "                           'Suzanne VASSE','Bessonnier','Yuyu','G. V. A. P','Mamiemonik49','Wondering Human Being',\n",
    "                           'Brig66 matricule 2705','Annie Lauvaux','Florquin Sylvie','Christine','Sandra Laguilliez','ğŸ’Les Mots de CathğŸ’',\n",
    "                           'ValÃ©rie Gross','MESNIL CÃ©cile','Sacha Benhamou ğŸŒğŸ‡ºğŸ‡¦ğŸ‡¹','Florence Cothier','VahineHapyğŸ¢ #Unionpopulaire ğŸ¢','francine Ortiz',\n",
    "                           'CÃ©line','Miria','CONSTANTINAğŸ¥•ğŸ¥•ğŸ¥• 34ğŸ‡²ğŸ‡¹','ğ”¼ğ•ğ•–ğ•ğ•ğ•– â„™ ğŸ¦„','Cyrille V.','Melanie Carpentier','CÃ©line Neumann','Mum89000/13â€¦',\n",
    "                           'Virginie Joron','Nathalie Lepert','CÃ©lia Ibanez','zorah Ï† ğŸ¢ âœŒï¸ ğŸ•Š','Inanna','PatouğŸŒ·ğŸ¦‹ğŸŒ»','Rose Mana')]:\n",
    "    df['Sexe']='F'\n",
    "else:\n",
    "    df['Sexe']='Indef'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
